# üçΩÔ∏è **FEATURE STORE FEAST**

*Guide complet d'impl√©mentation et d'int√©gration*
*Plateforme MLOps Scoring Automatique*

---

## üìã **APER√áU**

Le Feature Store Feast fournit une gestion centralis√©e des features ML avec s√©paration entre stockage offline (historique) et online (temps r√©el). Il assure la coh√©rence des features entre entra√Ænement et inf√©rence.

### **Composants Impl√©ment√©s**
- ‚úÖ **Feature Registry** : Catalogue centralis√© des features
- ‚úÖ **Offline Store** : PostgreSQL pour donn√©es historiques
- ‚úÖ **Online Store** : Redis pour features temps r√©el
- ‚úÖ **Feature Services** : APIs sp√©cialis√©es par cas d'usage
- ‚úÖ **Materialization** : Synchronisation automatique offline‚Üíonline

---

## üèóÔ∏è **ARCHITECTURE**

### **Flux de Donn√©es**
```
Sources de Donn√©es (PostgreSQL, Kafka, APIs)
        ‚Üì
Ingestion & Transformation (Spark, Python)
        ‚Üì
Offline Store (PostgreSQL - donn√©es historiques)
        ‚Üì
Materialization (Feast Jobs)
        ‚Üì
Online Store (Redis - features temps r√©el)
        ‚Üì
APIs de Scoring (FastAPI, mod√®les ML)
```

### **Feature Views D√©finis**

#### **1. Customer Features (365 jours TTL)**
```python
customer_features = FeatureView(
    name="customer_features",
    entities=[customer],
    schema=[
        "age", "income", "employment_years", "credit_history_length",
        "num_credit_lines", "debt_ratio", "revolving_utilization",
        "late_payment_ratio_6m", "late_payment_ratio_12m",
        "avg_transaction_amount_3m", "transaction_count_3m",
        "high_risk_transaction_ratio", "geographic_risk_score"
    ]
)
```

#### **2. Transaction Features (90 jours TTL)**
```python
transaction_features = FeatureView(
    name="transaction_features",
    entities=[customer],
    schema=[
        "total_transaction_amount_7d", "total_transaction_amount_30d",
        "avg_daily_transactions_30d", "max_transaction_amount_30d",
        "transaction_frequency_score", "unusual_transaction_pattern",
        "merchant_risk_score", "international_transaction_ratio"
    ]
)
```

#### **3. Real-time Features (24h TTL)**
```python
real_time_features = FeatureView(
    name="real_time_features",
    entities=[customer],
    schema=[
        "current_balance", "last_transaction_amount", "login_attempts_24h",
        "device_fingerprint_score", "ip_risk_score", "session_duration"
    ]
)
```

### **Feature Services**

#### **Credit Scoring Service**
```python
credit_scoring_service = FeatureService(
    name="credit_scoring_service",
    features=[
        customer_features[["age", "income", "debt_ratio", "revolving_utilization"]],
        transaction_features[["total_transaction_amount_30d", "unusual_transaction_pattern"]],
        real_time_features[["current_balance", "login_attempts_24h"]],
        credit_scoring_features  # Features calcul√©es on-demand
    ]
)
```

#### **Fraud Detection Service**
```python
fraud_detection_service = FeatureService(
    name="fraud_detection_service",
    features=[
        transaction_features[["max_transaction_amount_30d", "merchant_risk_score"]],
        real_time_features[["last_transaction_amount", "ip_risk_score"]],
        credit_scoring_features[["fraud_probability"]]
    ]
)
```

---

## üöÄ **D√âPLOIEMENT**

### **1. Pr√©requis**
```bash
# Services requis
‚úÖ PostgreSQL (offline store)
‚úÖ Redis (online store) - optionnel pour d√©marrage
‚úÖ MinIO (registry storage)
‚úÖ Kubernetes cluster
```

### **2. D√©ploiement**
```bash
# Appliquer la configuration
kubectl apply -f feature-store/feast-configmap.yaml
kubectl apply -f feature-store/feast-deployment.yaml

# Attendre le d√©marrage
kubectl wait --for=condition=ready pod -l app=feast-feature-server

# Initialiser le feature store
cd feature-store
./setup-feast.sh
```

### **3. V√©rification**
```bash
# Port-forward
kubectl port-forward svc/feast-feature-server-service 80:80

# Test de sant√©
curl http://localhost/health

# Lister les features
curl http://localhost/api/v1/features
```

---

## üîß **INT√âGRATION AVEC L'API DE SCORING**

### **1. Configuration FastAPI**

#### **Installation des d√©pendances**
```python
# requirements.txt
feast==0.34.0
redis==4.5.4
pandas==2.0.3
```

#### **Configuration Feast**
```python
# scoring_api/feast_client.py
from feast import FeatureStore
import pandas as pd
from datetime import datetime

class FeastClient:
    def __init__(self):
        self.store = FeatureStore(repo_path="/opt/feast/repo")
        self.feature_service = self.store.get_feature_service("credit_scoring_service")

    def get_features_for_scoring(self, customer_ids: list) -> pd.DataFrame:
        """R√©cup√®re les features pour le scoring de cr√©dit"""

        # Features pour les clients sp√©cifi√©s
        entity_df = pd.DataFrame({
            "customer_id": customer_ids,
            "event_timestamp": [datetime.now()] * len(customer_ids)
        })

        # R√©cup√©ration des features depuis le Feature Store
        features_df = self.store.get_online_features(
            features=self.feature_service,
            entity_rows=entity_df.to_dict('records')
        ).to_df()

        return features_df

    def push_real_time_features(self, customer_id: str, features: dict):
        """Pousse des features temps r√©el dans le store"""

        entity_df = pd.DataFrame({
            "customer_id": [customer_id],
            "event_timestamp": [datetime.now()],
            **features
        })

        # Push vers le PushSource
        self.store.push("real_time_push_source", entity_df)

# Instance globale
feast_client = FeastClient()
```

### **2. Int√©gration dans l'API Scoring**

#### **Endpoint de Scoring**
```python
# scoring_api/main.py
from fastapi import FastAPI, HTTPException
from feast_client import feast_client
import joblib
import pandas as pd

app = FastAPI(title="Credit Scoring API with Feast")

# Charger le mod√®le
model = joblib.load("models/credit_scoring_model.pkl")

@app.post("/score")
async def score_credit(request: ScoringRequest):
    try:
        # R√©cup√©ration des features depuis Feast
        features_df = feast_client.get_features_for_scoring([request.customer_id])

        if features_df.empty:
            raise HTTPException(status_code=404, detail="Customer features not found")

        # Pr√©paration des donn√©es pour le mod√®le
        model_features = features_df[[
            'age', 'income', 'employment_years', 'credit_history_length',
            'num_credit_lines', 'debt_ratio', 'revolving_utilization',
            'total_transaction_amount_30d', 'avg_daily_transactions_30d',
            'transaction_frequency_score', 'unusual_transaction_pattern',
            'current_balance', 'login_attempts_24h', 'device_fingerprint_score',
            'combined_risk_score', 'creditworthiness_index', 'fraud_probability'
        ]]

        # Pr√©diction
        score_proba = model.predict_proba(model_features)[0]
        credit_score = int(300 + (score_proba[1] * 550))  # Conversion en score FICO-like

        # Mise √† jour des features temps r√©el
        feast_client.push_real_time_features(request.customer_id, {
            "last_scoring_request": datetime.now().timestamp(),
            "scoring_score": credit_score,
            "scoring_probability": score_proba[1]
        })

        return {
            "customer_id": request.customer_id,
            "credit_score": credit_score,
            "risk_level": "LOW" if credit_score > 700 else "MEDIUM" if credit_score > 600 else "HIGH",
            "confidence": float(score_proba[1]),
            "features_used": len(model_features.columns),
            "timestamp": datetime.now().isoformat()
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Scoring error: {str(e)}")
```

### **3. Endpoint de Mise √† Jour Temps R√©el**

```python
@app.post("/update-features/{customer_id}")
async def update_customer_features(customer_id: str, features: Dict[str, Any]):
    """Met √† jour les features temps r√©el d'un client"""

    try:
        feast_client.push_real_time_features(customer_id, features)
        return {"status": "success", "customer_id": customer_id, "features_updated": len(features)}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Feature update error: {str(e)}")
```

---

## üìä **GESTION DES DONN√âES**

### **1. Chargement des Donn√©es Historiques**

#### **Script de Chargement**
```python
# scripts/load_historical_data.py
import pandas as pd
from feast import FeatureStore
from datetime import datetime, timedelta
import numpy as np

def load_customer_features():
    """Charge les features clients depuis PostgreSQL"""

    # Simulation de donn√©es (remplacer par vraie requ√™te)
    customers = []
    for i in range(1000):
        customers.append({
            "customer_id": f"CUST{i:04d}",
            "event_timestamp": datetime.now() - timedelta(days=np.random.randint(0, 365)),
            "age": np.random.randint(18, 80),
            "income": np.random.normal(50000, 15000),
            "employment_years": np.random.randint(0, 40),
            "credit_history_length": np.random.randint(0, 240),
            "num_credit_lines": np.random.randint(0, 10),
            "debt_ratio": np.random.uniform(0, 1),
            "revolving_utilization": np.random.uniform(0, 1),
            "late_payment_ratio_6m": np.random.uniform(0, 1),
            "late_payment_ratio_12m": np.random.uniform(0, 1),
            "avg_transaction_amount_3m": np.random.normal(500, 200),
            "transaction_count_3m": np.random.randint(0, 100),
            "transaction_count_6m": np.random.randint(0, 200),
            "high_risk_transaction_ratio": np.random.uniform(0, 1),
            "geographic_risk_score": np.random.uniform(0, 1),
            "behavioral_score": np.random.uniform(0, 1)
        })

    df = pd.DataFrame(customers)

    # Sauvegarde dans MinIO/S3
    df.to_parquet("s3a://data-lake/scoring/customers/customer_features.parquet")

    return df

def load_transaction_features():
    """Charge les features de transaction"""

    transactions = []
    for i in range(1000):
        transactions.append({
            "customer_id": f"CUST{i:04d}",
            "event_timestamp": datetime.now() - timedelta(days=np.random.randint(0, 90)),
            "total_transaction_amount_7d": np.random.normal(1000, 500),
            "total_transaction_amount_30d": np.random.normal(4000, 1500),
            "avg_daily_transactions_30d": np.random.normal(10, 5),
            "max_transaction_amount_30d": np.random.normal(1000, 300),
            "transaction_frequency_score": np.random.uniform(0, 1),
            "unusual_transaction_pattern": np.random.randint(0, 2),
            "merchant_risk_score": np.random.uniform(0, 1),
            "international_transaction_ratio": np.random.uniform(0, 1),
            "cash_withdrawal_ratio": np.random.uniform(0, 1),
            "online_transaction_ratio": np.random.uniform(0, 1),
            "weekend_transaction_ratio": np.random.uniform(0, 1),
            "late_night_transaction_ratio": np.random.uniform(0, 1)
        })

    df = pd.DataFrame(transactions)
    df.to_parquet("s3a://data-lake/scoring/transactions/transaction_features.parquet")

    return df

if __name__ == "__main__":
    print("Chargement des donn√©es historiques...")

    customer_df = load_customer_features()
    transaction_df = load_transaction_features()

    print(f"‚úÖ {len(customer_df)} features clients charg√©es")
    print(f"‚úÖ {len(transaction_df)} features transactions charg√©es")

    # Initialiser Feast et materialiser
    store = FeatureStore(repo_path="/opt/feast/repo")
    store.materialize_incremental(end_date=datetime.now())
    print("‚úÖ Materialization termin√©e")
```

### **2. Materialization Automatique**

#### **Job Kubernetes**
```yaml
# feature-store/materialization-job.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: feast-materialization-cron
spec:
  schedule: "*/30 * * * *"  # Toutes les 30 minutes
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: feast-materialization
            image: feastdev/feature-server:0.34.0
            command:
            - feast
            - materialize-incremental
            - --feature-views
            - customer_features,transaction_features
            env:
            - name: FEAST_REPO_PATH
              value: "/opt/feast/repo"
            volumeMounts:
            - name: feast-repo
              mountPath: /opt/feast/repo
          volumes:
          - name: feast-repo
            configMap:
              name: feast-feature-repo
          restartPolicy: OnFailure
```

---

## üîç **MONITORING ET OBSERVABILIT√â**

### **M√©triques Feast**
```bash
# M√©triques disponibles
curl http://localhost/metrics

# M√©triques cl√©s:
# - feast_feature_serving_request_count
# - feast_feature_serving_request_duration
# - feast_materialization_duration
# - feast_online_store_latency
```

### **Dashboard Grafana**
```json
// Panel: Feature Serving Latency
{
  "title": "Feature Serving Latency",
  "targets": [
    {
      "expr": "histogram_quantile(0.95, rate(feast_feature_serving_request_duration_bucket[5m]))",
      "legendFormat": "95th percentile"
    }
  ]
}

// Panel: Materialization Status
{
  "title": "Materialization Success Rate",
  "targets": [
    {
      "expr": "rate(feast_materialization_success_total[1h]) / rate(feast_materialization_total[1h]) * 100",
      "legendFormat": "Success Rate %"
    }
  ]
}
```

### **Alertes Prometheus**
```yaml
# Alertes pour le Feature Store
- alert: FeastServingHighLatency
  expr: histogram_quantile(0.95, rate(feast_feature_serving_request_duration_bucket[5m])) > 1
  for: 5m
  labels:
    severity: warning
  annotations:
    summary: "Feature serving latency √©lev√©e"
    description: "La latence de service des features d√©passe 1 seconde"

- alert: FeastMaterializationFailed
  expr: increase(feast_materialization_failed_total[1h]) > 0
  for: 5m
  labels:
    severity: critical
  annotations:
    summary: "√âchec de materialization Feast"
    description: "La materialization automatique des features a √©chou√©"
```

---

## üß™ **TESTS ET VALIDATION**

### **1. Tests Unitaires**
```python
# tests/test_feast_integration.py
import pytest
from feast_client import feast_client
import pandas as pd

def test_feature_retrieval():
    """Test r√©cup√©ration de features"""
    customer_ids = ["CUST0001", "CUST0002"]
    features_df = feast_client.get_features_for_scoring(customer_ids)

    assert len(features_df) == 2
    assert "age" in features_df.columns
    assert "income" in features_df.columns

def test_real_time_feature_push():
    """Test push de features temps r√©el"""
    features = {
        "current_balance": 1500.50,
        "last_transaction_amount": 250.00,
        "login_attempts_24h": 3
    }

    result = feast_client.push_real_time_features("CUST0001", features)
    assert result is not None

def test_feature_service():
    """Test du Feature Service"""
    store = feast_client.store
    service = store.get_feature_service("credit_scoring_service")

    assert service.name == "credit_scoring_service"
    assert len(service.features) > 0
```

### **2. Tests d'Int√©gration**
```bash
# Test end-to-end
./feature-store/test-feast-integration.sh

# Tests attendus:
‚úÖ Features disponibles dans le store
‚úÖ R√©cup√©ration online fonctionnelle
‚úÖ Materialization automatique
‚úÖ Int√©gration API scoring
```

---

## üìà **PERFORMANCES ET OPTIMISATION**

### **Optimisations Impl√©ment√©es**

#### **1. TTL (Time To Live)**
- **Customer features** : 365 jours (donn√©es stables)
- **Transaction features** : 90 jours (activit√© r√©cente)
- **Real-time features** : 24 heures (donn√©es volatiles)

#### **2. Indexes et Partitionnement**
```sql
-- Indexes dans PostgreSQL
CREATE INDEX idx_customer_features_customer_id ON feast.customer_features (customer_id);
CREATE INDEX idx_transaction_features_customer_id ON feast.transaction_features (customer_id);
CREATE INDEX idx_event_timestamp ON feast.customer_features (event_timestamp);
```

#### **3. Cache Redis**
```yaml
# Configuration Redis pour performances
online_store:
  type: redis
  connection_string: redis-service.default.svc.cluster.local:6379
  key_ttl_seconds: 86400  # 24h TTL
```

### **M√©triques de Performance**
- **Latence moyenne** : < 50ms pour r√©cup√©ration online
- **Throughput** : 1000+ requ√™tes/seconde
- **Disponibilit√©** : 99.9% SLA
- **Freshness** : < 30min pour materialization

---

## üö® **D√âPANNAGE**

### **Probl√®mes Courants**

#### **1. Features Non Disponibles**
```bash
# V√©rifier la materialization
kubectl logs deployment/feast-materialization-job

# Relancer la materialization
kubectl exec deployment/feast-materialization-job -- feast materialize-incremental
```

#### **2. Erreur de Connexion**
```bash
# V√©rifier PostgreSQL
kubectl exec -n storage postgresql-0 -- pg_isready -h localhost

# V√©rifier Redis
kubectl exec redis-pod -- redis-cli ping
```

#### **3. Probl√®me de Registry**
```bash
# V√©rifier MinIO
kubectl port-forward svc/minio-service 9000:9000 -n storage
curl http://localhost:9000/minio/health/live
```

### **Commandes de Debug**
```bash
# Inspecter le Feature Store
kubectl exec feast-pod -- feast feature-views list

# Voir les entit√©s
kubectl exec feast-pod -- feast entities list

# Status du registry
kubectl exec feast-pod -- feast registry-dump
```

---

## üéØ **IMPACT BUSINESS**

| Aspect | Avant | Apr√®s | Am√©lioration |
|--------|-------|-------|--------------|
| **Consistency** | Manuelle | Automatis√©e | üîº **100%** |
| **Freshness** | Batch daily | Near real-time | üîº **95%** |
| **Reusability** | Duplication | Centralis√©e | üîº **80%** |
| **Development** | Complexe | Standardis√© | üîº **70%** |
| **Maintenance** | Difficile | Automatis√©e | üîº **90%** |

### **B√©n√©fices Op√©rationnels**
- **Coh√©rence** : Features identiques entre entra√Ænement et production
- **Productivit√©** : R√©utilisation des features across mod√®les
- **Performance** : Cache online pour latence minimale
- **√âvolutivit√©** : Architecture cloud-native
- **Gouvernance** : Catalogue centralis√© et versionn√©

---

**üçΩÔ∏è Feature Store Feast op√©rationnel pour features ML centralis√©es !**

*Offline store PostgreSQL + Online store Redis + Materialization automatique*
*Pr√™t pour int√©gration avec APIs de scoring et mod√®les ML* üéØ